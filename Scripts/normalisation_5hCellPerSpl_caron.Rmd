---
title: "CRUK CI Summer School 2020 - introduction to single-cell RNA-seq analysis"
subtitle: 'Normalisation - Caron data set - 500 cells per sample'

author: "Stephane Ballereau"
output:
  html_document:
    df_print: paged
    toc: yes
    number_sections: true
    code_folding: hide
  html_notebook:
    code_folding: hide
    toc: yes
    toc_float: yes
    number_sections: true
  html_book:
    code_folding: hide
---

<!--
params:
  projDir: "/ssd/personal/baller01/20200511_FernandesM_ME_crukBiSs2020"
  dirRel: ".."
  inpDirBit: "AnaWiSce/Ana1"
  outDirBit: "AnaWiSce/Ana1"
  bookType: "mk"
  cacheBool: FALSE
-->

# Normalisation - Caron set {#NormalisationCaron5hcpsTop}

```{r norm_Caron.knitr_options, echo=FALSE, results="hide", message=FALSE, dev="CairoPNG"}
library(knitr)
# add 'dev="CairoPNG"' if X11 is not available
#opts_chunk$set(dev="CairoPNG")

cacheBool <- !TRUE
require(knitr)
opts_chunk$set(error=FALSE, message=FALSE, warning=FALSE, cache=cacheBool)
opts_chunk$set(fig.width=7, fig.height=7)
options(bitmapType='cairo') # if X11 is not available
opts_chunk$set(dev="CairoPNG") # if X11 is not available
set.seed(123) # for reproducibility
```

Sources: chapters on normalisation in the
[OSCA book](https://osca.bioconductor.org/normalization.html) and the
[Hemberg group materials](https://scrnaseq-course.cog.sanger.ac.uk/website/index.html).

## Learning objectives

<!--
<style>
div.blue {background-color:#e6f0ff; border-radius: 5px; padding: 20px;}
</style>
<div class = "blue">
-->

* Understand why normalisation is required
* Understand concepts of two normalisation methods
  * deconvolution
  * SCTransform 

<!--
</div>
-->

<!--
* Understand why normalisation is required
  * differences in sequencing coverage between libraries
    * due to low input material, differences in cDNA capture and PCR amplification
  * differences between cells aould be tecnical, not biological
  * comparisons between cells would not be meaningful
* deconvolution
  * compute for each cell a series of scaling factors
* SCTransform
  * elimination of the correlation between gene expression levels and library size,
    using by regression
-->

## Why normalise?

Systematic differences in sequencing coverage between libraries occur because of
low input material, differences in cDNA capture and PCR amplification.
Normalisation removes such differences so that differences between cells are not
technical but biological, allowing meaningful comparison of expression profiles
between cells. Normalisation and batch correction have different aims.
Normalisation addresses technical differences only, while batch correction
considers both technical and biological differences.


<!-- PARAMS and LIBRARIES -->

```{r Caron_variables_norm}
#normPlotDirBit <- "Plots/Norm" # not use anymore

projDir <- ".." # or /home/ubuntu/CourseMaterials/scRNAseq
dirRel <- ".."
outDirBit <- "CourseMaterials"
setName <- tolower("Caron")
writeRds <- TRUE # FALSE

# create folder for plots for normalisation:
##dir.create(sprintf("%s/%s/%s", projDir, outDirBit, normPlotDirBit),
##           showWarnings = FALSE,
##recursive = TRUE)
```

```{r Caron_libraries_norm, include=FALSE, results='hide', message=FALSE, warning=FALSE}
library(scater)
library(scran)
library(ggplot2)
library(dplyr)
library(tidyr)
library(BiocSingular)
library(BiocParallel)
library(glue)

bpp <- MulticoreParam(7)

library(Cairo) # if X11 is not available
```

## Load object

We will load the R object created after QC.

```{r Caron_norm_readIn_5hCellPerSpl, cache.lazy = FALSE}
# Read object in:
tmpFn <- "../CourseMaterials/Robjects/Caron_filtered.rds"
sce <- readRDS(tmpFn)
sce
```

```{r}
# PATCH names
#samplesheet <- readr::read_tsv("../CourseMaterials/Data/sample_sheet.tsv")
#samplesheet %>%
#	as.data.frame() %>%
#	DT::datatable(rownames = FALSE, options = list(dom="tpl", nrows=20))

dd <- colData(sce) %>%
  data.frame() %>%
  rename(SampleName=Sample) %>% # TODO: change that in preProc
  DataFrame()

colData(sce) <- dd  
```

Sample sheet:

```{r Caron_norm_sampleSheet}
colData(sce) %>%
  data.frame() %>%
  select(SampleName, SampleId, SampleGroup) %>%
  group_by(SampleName, SampleId, SampleGroup) %>%
  summarise(nbCells=n()) %>%
  DT::datatable(rownames = FALSE,
                options = list(dom="tpl", pageLength = 15, nrows=20))
```

Subsample cells down to 500 per sample

```{r Caron_norm_downsample}
setSuf <- "_5hCellPerSpl"
nbCells <- 500

# have new list of cell barcodes for each sample
sce.master <- sce
vec.bc <- colData(sce.master) %>%
	data.frame() %>%
	filter(!SampleId == "SRR9264351") %>%
	group_by(SampleName) %>%
	sample_n(nbCells) %>%
	pull(Barcode)
```



Subset cells from the SCE object:

```{r Caron_subset_sce}
tmpInd <- which(colData(sce.master)$Barcode %in% vec.bc) # mind QC metrics will be wrong
sce <- sce.master[,tmpInd]
rm(sce.master)
```

<!-- Check columns data: -->

```{r Caron_norm_sampleSheet_postDownSampling}
colData(sce) %>%
  data.frame() %>%
  select(SampleName, SampleId, SampleGroup) %>%
  group_by(SampleName, SampleId, SampleGroup) %>%
  summarise(nbCells=n()) %>%
  DT::datatable(rownames = FALSE,
                options = list(dom="tpl", pageLength = 15, nrows=20))
```

<!--
# mind that genes were filtered using all cells, not just those sampled here.
-->

<!-- We write the R object to '`r sprintf("%s_postQc%s.Rds", setName, setSuf)`'. -->
We write the R object to '`r glue("{setName}_postQc{setSuf}.Rds")`'.

```{r Caron_downsample_write, eval=writeRds}
# Write object to file
#getwd()
tmpFn <- sprintf("%s/%s/Robjects/%s_postQc%s.Rds",
		 projDir, outDirBit, setName, setSuf)
saveRDS(sce, tmpFn)
```

```{r Caron_downsample_read, eval=TRUE, cache.lazy = FALSE}
# Write object to file
tmpFn <- sprintf("%s/%s/Robjects/%s_postQc%s.Rds",
		 projDir, outDirBit, setName, setSuf)
sce <- readRDS(tmpFn)
```

## Scaling normalization

In scaling normalization, the “normalization factor” is an estimate of the
library size relative to the other cells. Steps usually include: computation of
a cell-specific 'scaling' or 'size' factor that represents the relative bias in
that cell and division of all counts for the cell by that factor to remove that
bias. Assumption: any cell specific bias will affect genes the same way.

Scaling methods typically generate normalised counts-per-million (CPM) or 
transcripts-per-million (TPM) values that address the effect of sequencing depth.
These values however typically have a variance that increases with their mean 
(heteroscedasticity) while most statistical methods assume a stable variance,
which does not vary with the mean (homoscedasticity). A widely used 'variance
stabilising transformation' is the log transformation (often log2). This works
fine for highly expressed genes (as in bulk RNA-seq) but less so for sparse
scRNA-seq data.

### CPM

Convert raw counts to counts-per-million (CPM) for each cell by dividing counts
by the library size then multiplying by 1.000.000. Mind that this does not
adress compositional bias caused by highly expressed genes that are also
differentially expressed between cells. In `scuttle` CPMs are computed as follows:

```{r Caron_calc_cpm}
calc_cpm <- function (expr_mat, spikes = NULL) 
{
    norm_factor <- colSums(expr_mat[-spikes, ])
    return(t(t(expr_mat)/norm_factor)) * 10^6
}
```

We will use `scuttle`'s calculateCPM()

### DESeq's size factor

For each gene, compute geometric mean across cells. for each cell compute for 
each gene the ratio of its expression to its geometric mean, and derive the 
cell's size factor as the median ratio across genes. Not suitable for sparse
scRNA-seq data as the geometric is computed on non-zero values only. This method
is also known as 'Relative Log Expression' (RLE) in `edgeR` and `scater`. 

Example code:

```{r Caron_calc_sf}
calc_sf <- function (expr_mat, spikes = NULL) 
{
    geomeans <- exp(rowMeans(log(expr_mat[-spikes, ])))
    SF <- function(cnts) {
        median((cnts/geomeans)[(is.finite(geomeans) &
				geomeans > 0)])
    }
    norm_factor <- apply(expr_mat[-spikes, ], 2, SF)
    return(t(t(expr_mat)/norm_factor))
}
```

### Weighted Trimmed mean of M-values

To compute weighted Trimmed mean of M-values (TMM), a given cell is chosen as a
reference to use in computation for other cells. The M-values are gene-wise
log2-fold changes between cells. Trimming entails the removal of the top and
bottom 30% of values. The size factor is computed as the average for the remaining
cells with a weight according to inverse variances. This method assumes that
most genes are not differentially expressed, and the 40% of genes left after 
trimming may include many zero counts.

```{r calcNormFactors_comp_norm_Caron_5hCellPerSpl}
sizeFactors(sce) <- edgeR::calcNormFactors(counts(sce), method = "TMM")
```

### Library size normalization

For each cell, the library size factor is proportional to the library size such
that the average size factor across cell is one.

Advantage: normalised counts are on the same scale as the initial counts.

Compute size factors:

```{r librarySizeFactors_comp_norm_Caron_5hCellPerSpl}
lib.sf <- librarySizeFactors(sce)
summary(lib.sf)
```

Size factor distribution: wide range, typical of scRNA-seq data.

```{r librarySizeFactors_hist_norm_Caron_5hCellPerSpl}
#hist(log10(lib.sf), xlab="Log10[Size factor]", col='grey80')

dd <- data.frame("log10libSf"=log10(lib.sf))
ggplot(dd, aes(x=log10libSf)) + 
  geom_histogram(bins=50)
```

Assumption: absence of compositional bias; differential expression between two 
cells is balanced: upregulation in some genes is accompanied by downregulation 
of other genes. Not observed.

Inaccurate normalisation due to unaccounted-for composition bias affects the 
size of the log fold change measured between clusters, but less so the
clustering itself. It is thus sufficient to identify clusters and top marker 
genes.

### Deconvolution

Composition bias occurs when differential expression beteween two samples
or here cells is not balanced. For a fixed library size, identical in both cells,
upregulation of one gene in a cell will means fewer UMIs can be assigned to other
genes, which would then appear down regulated. Even if library sizes are allowed
to differ, with that for the cell with upregulation being higher, scaling
normalisation will reduce normalised counts. Non-upregulated would therefore
also appear downregulated. 

For bulk RNA-seq, composition bias is removed by assuming that most genes are
not differentially expressed between samples, so that differences in non-DE 
genes would amount to the bias, and used to compute size factors.

Given the sparsity of scRNA-seq data, the methods are not appropriate.

The method below increases read counts by pooling cells into groups, computing
size factors within each of these groups and scaling them so they are comparable
across clusters. This process is repeated many times, changing pools each time
to collect several size factors for each cell, from which is derived a single
value for that cell.

<!--
see DESeq2 estimateSizeFactorsFromMatrix
see edgeR calcNormFactors
-->

```{r scran_Fig3_Caron}
tmpFn <- sprintf("%s/Images/scran_Fig3.png", "..")
knitr::include_graphics(tmpFn, auto_pdf = TRUE)
rm(tmpFn)
```

Cluster cells then normalise.

#### Cluster cells

```{r comp_quickClus_norm_Caron_5hCellPerSpl, eval=writeRds}
set.seed(100) # clusters with PCA from irlba with approximation
clust <- quickCluster(sce, BPPARAM=bpp) # slow with all cells.
table(clust)

# write to file
##tmpFn <- sprintf("%s/%s/Robjects/%s_sce_nz_quickClus%s.Rds",
##		 projDir, outDirBit, setName, setSuf)
##saveRDS(clust, tmpFn)
```

```{r load_quickClus_norm_Caron_5hCellPerSpl, cache.lazy = FALSE, eval=FALSE}
# read from file
tmpFn <- sprintf("%s/%s/Robjects/%s_sce_nz_quickClus%s.Rds",
		 projDir, outDirBit, setName, setSuf)
clust <- readRDS(tmpFn)
```

#### Compute size factors

```{r calculateSumFactors_norm_Caron_5hCellPerSpl, eval=writeRds}
#deconv.sf <- calculateSumFactors(sce, cluster=clust)
sce <- computeSumFactors(sce,
			 cluster = clust,
			 min.mean = 0.1,
			 BPPARAM = bpp)
deconv.sf <- sizeFactors(sce)

# write to file
##tmpFn <- sprintf("%s/%s/Robjects/%s_sce_nz_deconvSf%s.Rds",
##		 projDir, outDirBit, setName, setSuf)
##saveRDS(deconv.sf, tmpFn)
```

```{r load_deconvSf_norm_Caron_5hCellPerSpl, cache.lazy = FALSE, eval=FALSE}
# read from file
tmpFn <- sprintf("%s/%s/Robjects/%s_sce_nz_deconvSf%s.Rds",
		 projDir, outDirBit, setName, setSuf)
deconv.sf <- readRDS(tmpFn)
```

```{r}
summary(deconv.sf)
```

Plot deconvolution size factors against library size factors:

```{r scatter_deconvSf_libSf_plot_norm_Caron_5hCellPerSpl, eval=FALSE}
plot(lib.sf,
     deconv.sf,
     xlab="Library size factor",
     ylab="Deconvolution size factor",
     log='xy',
     pch=16,
     col=as.integer(factor(sce$SampleGroup)))
abline(a=0, b=1, col="red")
```

```{r scatter_deconvSf_libSf_colBy_plot_norm_Caron_5hCellPerSpl}

sce <- addPerFeatureQC(sce, BPPARAM = bpp) # PATCH

colData(sce)$cell_sparsity <- 1 - (colData(sce)$detected / nrow(sce))
rowData(sce)$gene_sparsity <- (100 - rowData(sce)$detected) / 100

deconvDf <- data.frame(lib.sf, deconv.sf,
			"source_name" = sce$SampleGroup,
			"sum" = sce$sum,
			"mito_content" = sce$subsets_Mito_percent,
			"cell_sparsity" = sce$cell_sparsity)
```

```{r scatter_deconvSf_libSf_colBy_sourceName_plot_norm_Caron_5hCellPerSpl}
# colour by sample type
sp <- ggplot(deconvDf, aes(x=lib.sf, y=deconv.sf, col=source_name)) +
  geom_point()
sp
```

```{r scatter_deconvSf_libSf_colBy_sourceName_split_plot_norm_Caron_5hCellPerSpl, eval=FALSE}
# Split by sample type
sp + facet_wrap(~source_name)
```

```{r scatter_deconvSf_libSf_colBy_more_norm_Caron_allCells, eval=FALSE, include=FALSE}
# colour by library size
sp <- ggplot(deconvDf, aes(x=lib.sf, y=deconv.sf, col=sum)) +
  geom_point()
sp

# colour by mito. content
sp <- ggplot(deconvDf, aes(x=lib.sf, y=deconv.sf, col=mito_content)) +
  geom_point()
sp
```

```{r scatter_deconvSf_libSf_colBy_cellSpars_norm_Caron_allCells}
# colour by cell sparsity
sp <- ggplot(deconvDf, aes(x=lib.sf, y=deconv.sf, col=cell_sparsity)) +
  geom_point()
sp
```

#### Apply size factors

For each cell, raw counts for genes are divided by the size factor for that cell and log-transformed so downstream analyses focus on genes with strong relative differences. We use `scater::logNormCounts()`.

```{r logNormCounts_norm_Caron_5hCellPerSpl}
sce <- logNormCounts(sce) # adds logcounts
print(assayNames(sce))
```

#### Save object

```{r sce_copy_norm_Caron_5hCellPerSpl}
sceDeconv <- sce
```

```{r sce_write_norm_Caron_5hCellPerSpl, eval=writeRds}
# write to file
tmpFn <- sprintf("%s/%s/Robjects/%s_postDeconv%s.Rds",
		 projDir, outDirBit, setName, setSuf)
saveRDS(sceDeconv, tmpFn)
```

## Exercise 1

Exercise: apply the deconvolution normalisation on a single sample: ETV6-RUNX1_1 (aka GSM3872434).

You first load the same object we loaded earlier, then select cells for SampleName 'ETV6-RUNX1_1'. You will then cluster cells, compute and apply size factors.

## SCTransform

<!--
https://rawgit.com/ChristophH/sctransform/master/inst/doc/variance_stabilizing_transformation.html

vars.to.regress = c("S.Score", "G2M.Score")
vars.to.regress = c("percentMito","Sex")
-->

With scaling normalisation a correlation remains between the mean and variation
of expression (heteroskedasticity). This affects downstream dimensionality
reduction as the few main new dimensions are usually correlated with library
size. SCTransform addresses the issue by regressing library size out of raw
counts and providing residuals to use as normalized and variance-stabilized
expression values in downstream analysis. We will use the
[sctransform vignette](https://cran.r-project.org/web/packages/sctransform/index.html).

```{r counts_sct_Caron_5hCellPerSpl}
counts <- counts(sce)
print(class(counts))
print(dim(counts))
colnames(counts) <- colData(sce)$Barcode
```

### Inspect data

We will now calculate some properties and visually inspect the data. Our main interest is in the general trends not in individual outliers. Neither genes nor cells that stand out are important at this step, but we focus on the global trends.

Derive gene and cell attributes from the UMI matrix.

```{r attr_comp_sct_Caron_5hCellPerSpl}
gene_attr <- data.frame(mean = rowMeans(counts), 
                        detection_rate = rowMeans(counts > 0),
                        var = apply(counts, 1, var))
gene_attr$log_mean <- log10(gene_attr$mean)
gene_attr$log_var <- log10(gene_attr$var)
rownames(gene_attr) <- rownames(counts)
cell_attr <- data.frame(n_umi = colSums(counts),
                        n_gene = colSums(counts > 0))
rownames(cell_attr) <- colnames(counts)
```

Gene attributes:

```{r gene_attr_sct_Caron_5hCellPerSpl}
dim(gene_attr)
head(gene_attr)
```

Cell attributes:

```{r cell_attr_sct_Caron_5hCellPerSpl}
dim(cell_attr)
head(cell_attr)
```

Mean-variance relationship

For the genes, we can see that up to a mean UMI count of 0 the variance follows
the line through the origin with slop one, i.e. variance and mean are roughly
equal as expected under a Poisson model. However, genes with a higher average
UMI count show overdispersion compared to Poisson.

```{r attr_plot_sct_Caron_5hCellPerSpl}
ggplot(gene_attr, aes(log_mean, log_var)) + 
  geom_point(alpha=0.3, shape=16) + 
  geom_density_2d(size = 0.3) +
  geom_abline(intercept = 0, slope = 1, color='red')
```

Mean-detection-rate relationship

In line with the previous plot, we see a lower than expected detection rate in
the medium expression range. However, for the highly expressed genes, the rate
is at or very close to 1.0 suggesting that there is no zero-inflation in the
counts for those genes and that zero-inflation is a result of overdispersion,
rather than an independent systematic bias.

```{r scatter_detecRate_logMean_sct_Caron_5hCellPerSpl}
# add the expected detection rate under Poisson model
x = seq(from = -3, to = 2, length.out = 1000)
poisson_model <- data.frame(log_mean = x,
			    detection_rate = 1 - dpois(0, lambda = 10^x))
ggplot(gene_attr, aes(log_mean, detection_rate)) + 
  geom_point(alpha=0.3, shape=16) + 
  geom_line(data=poisson_model, color='red') +
  theme_gray(base_size = 8)
```

```{r scatter_nGene_nUmi_sct_Caron_5hCellPerSpl, eval=FALSE}
ggplot(cell_attr, aes(n_umi, n_gene)) + 
  geom_point(alpha=0.3, shape=16) + 
  geom_density_2d(size = 0.3)
```

### Transformation

"Based on the observations above, which are not unique to this particular data
set, we propose to model the expression of each gene as a negative binomial
random variable with a mean that depends on other variables. Here the other
variables can be used to model the differences in sequencing depth between
cells and are used as independent variables in a regression model. In order to 
avoid overfitting, we will first fit model parameters per gene, and then use
the relationship between gene mean and parameter values to fit parameters,
thereby combining information across genes. Given the fitted model parameters,
we transform each observed UMI count into a Pearson residual which can be
interpreted as the number of standard deviations an observed count was away
from the expected mean. If the model accurately describes the mean-variance
relationship and the dependency of mean and latent factors, then the result
should have mean zero and a stable variance across the range of expression."
[sctransform vignette](https://cran.r-project.org/web/packages/sctransform/index.html).

Estimate model parameters and transform data

The vst function estimates model parameters and performs the variance stabilizing
transformation. Here we use the log10 of the total UMI counts of a cell as 
variable for sequencing depth for each cell. After data transformation we plot 
the model parameters as a function of gene mean (geometric mean).

```{r comp_sct_Caron_5hCellPerSpl, warning=FALSE}
print(dim(counts))
# We use the Future API for parallel processing; set parameters here
future::plan(strategy = 'multicore', workers = 7)
options(future.globals.maxSize = 10 * 1024 ^ 3)

set.seed(44)
vst_out <- sctransform::vst(counts,
			    latent_var = c('log_umi'),
			    return_gene_attr = TRUE,
			    return_cell_attr = TRUE,
			    show_progress = FALSE)
sctransform::plot_model_pars(vst_out)
```

Inspect model

```{r model_show_sct_Caron_5hCellPerSpl}
print(vst_out$model_str)
```

We will look at several genes in more detail.

```{r plot_model_1_sct_Caron_5hCellPerSpl}
rowData(sce) %>%
	as.data.frame %>%
	filter(Symbol %in% c('MALAT1', 'RPL10', 'FTL'))

sctransform::plot_model(vst_out,
			counts,
			c('ENSG00000251562', 'ENSG00000147403', 'ENSG00000087086'),
			plot_residual = TRUE)
```

```{r plot_model_2_sct_Caron_5hCellPerSpl, eval=FALSE}
sctransform::plot_model(vst_out,
			counts,
			c('ENSG00000087086'),
			plot_residual = TRUE,
			show_nr = TRUE,
			arrange_vertical = FALSE)
```

Distribution of residual mean:

```{r plot_model_resMean_sct_Caron_5hCellPerSpl}
ggplot(vst_out$gene_attr, aes(residual_mean)) +
	geom_histogram(binwidth=0.01)
```

Distribution of residual variance:

```{r plot_model_resVar_sct_Caron_5hCellPerSpl}
ggplot(vst_out$gene_attr, aes(residual_variance)) +
	geom_histogram(binwidth=0.1) +
	geom_vline(xintercept=1, color='red') +
	xlim(0, 10)
```

Variance against mean (residuals):

```{r plot_model_resVar_resMean_sct_Caron_5hCellPerSpl}
ggplot(vst_out$gene_attr, aes(x=residual_mean, y=residual_variance)) +
	geom_point(alpha=0.3, shape=16) + 
	#xlim(0, 0.5) +
	#ylim(0, 10) +
	xlim(0, quantile(vst_out$gene_attr$residual_mean, probs=0.95)) +
	ylim(0, quantile(vst_out$gene_attr$residual_variance, probs=0.95)) +
	geom_density_2d()
```

Variance against mean (genes):

```{r plot_model_resVar_gMean_sct_Caron_5hCellPerSpl}
ggplot(vst_out$gene_attr,
       aes(log10(gmean), residual_variance)) +
       geom_point(alpha=0.3, shape=16) +
       geom_density_2d(size = 0.3)
```

Check genes with large residual variance:

```{r table_show_sct_Caron_5hCellPerSpl}
dd <- vst_out$gene_attr %>%
	arrange(-residual_variance) %>%
	slice_head(n = 22) %>%
	mutate(across(where(is.numeric), round, 2))

dd %>% tibble::rownames_to_column("ID") %>%
	left_join(as.data.frame(rowData(sce))[,c("ID", "Symbol")], "ID") %>%
	DT::datatable(rownames = FALSE)
```

<!-- Write outcome to file: -->

```{r table_write_sct_Caron_5hCellPerSpl, eval=FALSE}
# write to file
tmpFn <- sprintf("%s/%s/Robjects/%s_sce_nz_vst_out%s.Rds",
		 projDir, outDirBit, setName, setSuf)
saveRDS(vst_out, tmpFn)
```

Check transformed values:

```{r check_trans_sct_Caron_5hCellPerSpl}
print(dim(vst_out$y))
vst_out$y[1:10,1:5]

sce
print(assayNames(sce))
```

Genes that are expressed in fewer than 5 cells are not used and not returned,
so to add vst_out$y as an assay we need to remove the missing genes.

```{r subsetGenes_Caron_5hCellPerSpl}
# genes that are expressed in fewer than 5 cells are not used and not returned
# so to add vst_out$y as an assay we need to ditch the missing genes completely.
# https://github.com/ChristophH/sctransform/issues/27

sceOrig <- sce
sceOrig
tmpInd <- which(rownames(sce) %in% rownames(vst_out$y))
cols.meta <- colData(sceOrig)
rows.meta <- rowData(sceOrig)

new.counts <- counts(sceOrig)[tmpInd, ]
sce <- SingleCellExperiment(list(counts=new.counts))

# reset the column data on the new object
colData(sce) <- cols.meta
rowData(sce) <- rows.meta[tmpInd, ]
assayNames(sce)
```

```{r copyVstMat_sct_Caron_5hCellPerSpl}
sce
vstMat <- as(vst_out$y[rownames(sce),], "dgCMatrix")
# reading 10X data with vector above adds a prefix to sce colnames
# so we will not pass vstMat colnames when copying it in a assay slot,
# but must first check that barcodes are indeed in the same order
# in sce and vstMat.
all(colnames(vstMat) == sce$Barcode)
all(rownames(vstMat) == rownames(sce))
assay(sce, "sctrans_norm", withDimnames=FALSE) <- vstMat
#assayNames(sce) # check sctrans_norm is there
```

### Save SCE object

```{r sce_write_sct_Caron_5hCellPerSpl, eval=writeRds}
# write to file
tmpFn <- sprintf("%s/%s/Robjects/%s_postSct%s.Rds",
		 projDir, outDirBit, setName, setSuf)
saveRDS(sce, tmpFn)
```

## Exercise 2

Exercise: apply the SCTransform normalisation on a single sample: ETV6-RUNX1_1 (aka GSM3872434).

In exercise 1, you have made a new SCE object with cells for SampleName 'ETV6-RUNX1_1'.
You will now inspect the mean-variance relationship and apply SCTransform to that data.

## Effectiveness

```{r}
# We will use the SCE object keeping the deconvolution counts
sce <- sceDeconv
```

### log raw counts

```{r comp_pca_logRaw_Caron_5hCellPerSpl}
typeNorm <- "logRaw"

# approximate SVD with irlba
# irlba == implicitly restarted Lanczos bidiagonalization algorithm.
options(BiocSingularParam.default=IrlbaParam())

# Have raw counts on log2 scale:
assay(sce, "logcounts_raw") <- log2(counts(sce) + 1)

# Perform PCA:
set.seed(123)
sceRawPca <- runPCA(
  sce,
  exprs_values = "logcounts_raw"#,
  #BSPARAM=IrlbaParam(),
  #BSPARAM=RandomParam(),
  #BPPARAM=bpp
)
```

PCA plot for the '`r typeNorm`' counts in the `r setName` set.

```{r plot_pca_logRaw_Caron_5hCellPerSpl}
p <- plotPCA(
    sceRawPca,
    colour_by = "SampleName",
    size_by = "sum",
    shape_by = "SampleGroup"
) + ggtitle(sprintf("PCA plot for log raw counts: %s", typeNorm))

p
```

<!--
Cell-wise RLE for the '`r typeNorm`' counts in the `r setName` set.
Each cell is represented by a box plot showing the inter-quartile range in grey,
wiskers colour-coded by Sample.Name and the median as a black circle. 
-->

<!-- calc_cell_RLE -->

```{r}
calc_cell_RLE <- function (expr_mat, spikes = NULL) 
{
  # define RLE_gene function:
  # compute RLE for a given gene
  # if median expression for that gene is positive
  # then compute RLE: log(count in cell / median count across cells)/log2
    RLE_gene <- function(x) {
      #print(length(x))
      #print(median(unlist(x)))
        if (median(unlist(x)) > 0) {
            log((x + 1)/(median(unlist(x)) + 1))/log(2)
        }
        else {
            rep(NA, times = length(x))
        }
    }
    if (!is.null(spikes)) {
        RLE_matrix <- t(apply(expr_mat[-spikes, ], 1, RLE_gene))
    }
    else {
        RLE_matrix <- t(apply(expr_mat, 1, RLE_gene))
    }
    return(RLE_matrix)
    cell_RLE <- apply(RLE_matrix, 2, median, na.rm = T)
    #print(cell_RLE)
    return(cell_RLE)
}
```

```{r}
prepRleMat <- function(rleMat) {
	# derive long table for plotting
	dd <- rleMat %>%
	  data.frame() %>%
	  tibble::rownames_to_column("geneId") %>%
	  pivot_longer(!geneId, names_to = "Barcode", values_to = "rle")
	colDataTmp <- data.frame(
	  colData(sce)[,c("Barcode", "SampleGroup", "SampleName")]
	  )
	colDataTmp$Barcode <- gsub("-", ".", colDataTmp$Barcode)
	# merge
	dd2 <- dd %>%
	  left_join(colDataTmp, by="Barcode")
	return(dd2)
}
myRlePlot <- function(ddToShow, bcToGet=NULL, sortBool=TRUE) {
	# Have function for code chunk above
	if(!is.null(bcToGet)) {
	  ddToShow <- ddToShow %>% filter(Barcode %in% bcToGet)
	}

	ddToShowMedianRle <- ddToShow %>%
	  group_by(SampleName, Barcode) %>%
	  summarise(medianRle=median(rle,na.rm = TRUE))

	ddToShowMedianRleSorted <- ddToShowMedianRle %>%
	  group_by(SampleName) %>%
	  arrange(Barcode, .by_group = TRUE)

	ddToShowSort <- ddToShowMedianRleSorted$Barcode
  
	# set levels
	if(sortBool)
	{
	  ddToShowMedianRleSorted <- ddToShowMedianRle %>%
	  group_by(SampleName) %>%
	  arrange(medianRle, .by_group = TRUE)
	}
	  ddToShowSort <- ddToShowMedianRleSorted$Barcode

 	ddToShow$Barcode <- factor(ddToShow$Barcode,
                           levels=ddToShowSort)

	ddToShow <- ddToShow %>%
	  filter(!is.na(rle))
	p <- ggplot(ddToShow, aes(x=Barcode, y=rle, col=SampleName))
	p2 <- p +
	  stat_summary(geom = "pointrange", 
	        width = 0.20, fatten = 0,
	        mapping = aes(group = SampleName),
	        fun.data = function(x) {
	            c(y = median(x),
	              ymin = unname(quantile(x,probs=0.25)),
	              ymax = unname(quantile(x,probs=0.75))
	              )
	        }) +
	  stat_summary(geom = "crossbar", 
	        width = 0.20, fatten = 0,
	        color = "black",
	        fun.data = function(x) {
	            c(y = median(x),
	              ymin = median(x),
	              ymax = median(x)
	              )
	        }) +
	  ylab("Relative log expression") +
	  xlab("Sample") +
	  theme_classic() +
	  theme(axis.text.x = element_blank(), 
	        axis.ticks.x = element_blank(),
	        axis.line.x = element_blank()) +
	  geom_hline(yintercept = 0)
	return(p2)
}
```

```{r}
rawRleMat <- calc_cell_RLE(counts(sce))
colnames(rawRleMat) <- sce$Barcode

dd2 <- prepRleMat(rawRleMat)
p2 <- myRlePlot(dd2)
```

```{r}
p2
```

```{r, eval=FALSE}
p2 + facet_wrap(~SampleGroup)
```        
        
<!-- plotRLE with sceRawPca: fail -->

```{r plot_rle_logRaw_Caron_5hCellPerSpl, cache.lazy = FALSE, eval=FALSE}
# issue with NAs
p <- plotRLE(
    sceRawPca,
    exprs_values = "logcounts_raw",
    colour_by = "SampleName"
) + ggtitle(sprintf("RLE plot: %s", typeNorm))

p
```

<!-- plotRLE with sce raw: fail -->

```{r, eval=FALSE}
p <- plotRLE(
    sce,
    exprs_values = "counts",
    exprs_logged = FALSE,
    colour_by = "SampleName"
) + ggtitle(sprintf("RLE plot: %s", typeNorm))

p
```

### log CPM

```{r comp_pca_logCpm_Caron_5hCellPerSpl, cache.lazy = FALSE}
typeNorm <- "logCpm"

assay(sce, "logCpm") <- log2(calculateCPM(sce, size_factors = NULL)+1)

logCpmPca <- runPCA(
  sce,
  exprs_values = "logCpm"#,
  #BPPARAM=bpp
)
```

PCA plot for the '`r typeNorm`' counts in the `r setName` set.

```{r plot_pca_logCpm_Caron_5hCellPerSpl}
p <- plotPCA(
    logCpmPca,
    colour_by = "SampleName",
    size_by = "sum",
    shape_by = "SampleGroup"
) + ggtitle(sprintf("PCA plot: %s", typeNorm))

p
```

<!--
Cell-wise RLE for the '`r typeNorm`' counts in the `r setName` set.
-->

<!-- plotRLE fails -->

```{r plot_rle_logCpm_Caron_5hCellPerSpl, cache.lazy = FALSE, eval=FALSE}
p <- plotRLE(
    sce,
    exprs_values = "logCpm",
    colour_by = "SampleName"
) + ggtitle(sprintf("RLE plot: %s", typeNorm))

p
```

```{r}
cpmRleMat <- calc_cell_RLE(calculateCPM(sce, size_factors = NULL))
colnames(cpmRleMat) <- sce$Barcode

dd2 <- prepRleMat(cpmRleMat)
p2 <- myRlePlot(dd2)
```

```{r}
p2
```

<!-- p2 + coord_flip(), no need -->

```{r, eval=FALSE}
p2 + coord_flip() + theme(
  #axis.title.y=element_blank(),
  axis.text.y=element_blank(),
  axis.ticks.y=element_blank())
```

### scran

Normalised counts are stored in the 'logcounts' assay

```{r comp_pca_deconv_Caron_5hCellPerSpl}
typeNorm <- "scran"

scranPca <- runPCA(
  sceDeconv,
  exprs_values = "logcounts"#,
  #BPPARAM=bpp
)
```

PCA plot for the '`r typeNorm`' counts in the `r setName` set.

```{r plot_pca_deconv_Caron_5hCellPerSpl}
p <- plotPCA(
    scranPca,
    colour_by = "SampleName",
    size_by = "sum",
    shape_by = "SampleGroup"
) + ggtitle(sprintf("PCA plot: %s", typeNorm))

p
```

TSNE plot for the '`r typeNorm`' counts in the `r setName` set.

```{r comp_tsne_deconv_Caron_5hCellPerSpl}
typeNorm <- "scran"

reducedDim(sceDeconv, "TSNE_scran") <- reducedDim(
  runTSNE(sceDeconv,
	  exprs_values = "logcounts",
	  BPPARAM=bpp),
  "TSNE"
)
```

```{r plot_tsne_deconv_Caron_5hCellPerSpl}
p <- plotReducedDim(
  sceDeconv,
  dimred = "TSNE_scran",
  colour_by = "SampleName",
  size_by = "sum",
  shape_by = "SampleGroup"
) + ggtitle(sprintf("TSNE plot: %s", typeNorm))

p
```

UMAP plot for the '`r typeNorm`' counts in the `r setName` set.

```{r comp_umap_deconv_Caron_5hCellPerSpl}
typeNorm <- "scran"

reducedDim(sceDeconv, "UMAP_scran") <- reducedDim(
  runUMAP(sceDeconv,
	  exprs_values = "logcounts",
	  BPPARAM=bpp),
  "UMAP"
)
```

```{r plot_umap_deconv_Caron_5hCellPerSpl}
p <- plotReducedDim(
  sceDeconv,
  dimred = "UMAP_scran",
  colour_by = "SampleName",
  size_by = "sum",
  shape_by = "SampleGroup"
) + ggtitle(sprintf("UMAP plot: %s", typeNorm))

p
```

<!--
Cell-wise RLE for the '`r typeNorm`' counts in the `r setName` set.
-->

<!-- plotRLE with scranPca: fail --> 

```{r plot_rle_deconv_Caron_5hCellPerSpl, eval=FALSE}
p <- plotRLE(
    scranPca,
    exprs_values = "logcounts",
    colour_by = "SampleName"
) + ggtitle(sprintf("RLE plot: %s", typeNorm))

p
```

```{r}
deconvRleMat <- calc_cell_RLE(logcounts(scranPca))
colnames(deconvRleMat) <- sce$Barcode

dd2 <- prepRleMat(deconvRleMat)
p2 <- myRlePlot(dd2)
```

```{r}
p2
```

### SCTransform

<!--
Remember we kept the sctransform counts separate from the deconvolution counts
because the former filters out genes that are expressed in few cells by itself
-->

```{r comp_pca_sct_Caron_5hCellPerSpl, cache.lazy = FALSE}
tmpFn <- sprintf("%s/%s/Robjects/%s_postSct%s.Rds",
		 projDir, outDirBit, setName, setSuf)
sce <- readRDS(tmpFn)

typeNorm <- "sctrans"

reducedDim(sce, "PCA_sctrans_norm") <- reducedDim(
  runPCA(sce,
	 exprs_values = "sctrans_norm"#,
	 #BPPARAM=bpp
	 ),
  "PCA"
)
```

PCA plot for the '`r typeNorm`' counts in the `r setName` set.

```{r plot_pca_sct_Caron_5hCellPerSpl}
p <- plotReducedDim(
  sce,
  dimred = "PCA_sctrans_norm",
  colour_by = "SampleName",
  size_by = "sum",
  shape_by = "SampleGroup"
) + ggtitle(sprintf("PCA plot: %s", typeNorm))

p
```

<!--
somewhat surprising PCA plot
with cells tight along PC1 and PC2
-->

```{r}
percent.var <- attr(reducedDim(sce), "percentVar")
chosen.elbow <- PCAtools::findElbowPoint(percent.var)
chosen.elbow
```

```{r}
plot(percent.var, xlab="PC", ylab="Variance explained (%)")
abline(v=chosen.elbow, col="red")
```

TSNE plot for the '`r typeNorm`' counts in the `r setName` set.

```{r comp_tsne_sct_Caron_5hCellPerSpl, cache.lazy = FALSE}
typeNorm <- "sctrans"

reducedDim(sce, "TSNE_sctrans_norm") <- reducedDim(
  runTSNE(sce,
	  exprs_values = "sctrans_norm",
	  BPPARAM=bpp),
  "TSNE"
)
```

```{r plot_tsne_sct_Caron_5hCellPerSpl}
p <- plotReducedDim(
  sce,
  dimred = "TSNE_sctrans_norm",
  colour_by = "SampleName",
  size_by = "sum",
  shape_by = "SampleGroup"
) + ggtitle(sprintf("TSNE plot: %s", typeNorm))

p
```

UMAP plot for the '`r typeNorm`' counts in the `r setName` set.

```{r comp_umap_sct_Caron_5hCellPerSpl, cache.lazy = FALSE}
typeNorm <- "sctrans"

reducedDim(sce, "UMAP_sctrans_norm") <- reducedDim(
  runUMAP(sce,
	  exprs_values = "sctrans_norm",
	  BPPARAM=bpp),
  "UMAP"
)
```

```{r plot_umap_sct_Caron_5hCellPerSpl}
p <- plotReducedDim(
  sce,
  dimred = "UMAP_sctrans_norm",
  colour_by = "SampleName",
  size_by = "sum",
  shape_by = "SampleGroup"
) + ggtitle(sprintf("UMAP plot: %s", typeNorm))

p
```

Cell-wise RLE for the '`r typeNorm`' counts in the `r setName` set.
Each cell is represented by a box plot showing the inter-quartile range in grey,
wiskers colour-coded by Sample.Name and the median as a black circle. 

```{r plot_rle_sct_Caron_5hCellPerSpl, cache.lazy = FALSE}
p <- plotRLE(
    sce,
    exprs_values = "sctrans_norm",
    colour_by = "SampleName"
) + ggtitle(sprintf("RLE plot: %s", typeNorm))

p
```

```{r}
sctRleMat <- calc_cell_RLE(assay(sce, "sctrans_norm"))
colnames(sctRleMat) <- sce$Barcode

dd2 <- prepRleMat(deconvRleMat)
p2 <- myRlePlot(dd2, sortBool=FALSE)
```

```{r}
library(patchwork)
p/p2
```

## Session information

```{r}
sessionInfo()
```
